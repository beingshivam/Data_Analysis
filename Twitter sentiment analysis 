{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## install the streaming twitter jar in the notebook from the Github repo", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190521091214-0002\nKERNEL_ID = 253124bf-608c-402a-91c9-379ca2c171d7\nPixiedust database opened successfully\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.15</span>\n        </div>\n        ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.15, Latest is 1.1.16</div>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "\n                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n            ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<div>Please restart kernel after upgrading.</div>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Package already installed: https://github.com/ibm-watson-data-lab/spark.samples/raw/master/dist/streaming-twitter-assembly-1.6.jar\ndone\n"
                }
            ], 
            "source": "import pixiedust\njarPath = \"https://github.com/ibm-watson-data-lab/spark.samples/raw/master/dist/streaming-twitter-assembly-1.6.jar\"\npixiedust.installPackage(jarPath)\nprint(\"done\")"
        }, 
        {
            "source": "## Use Scala Bridge to run the command line version of the app\nFor instruction on how to set up the twitter and Tone Analyzer credentials, please refer to https://developer.ibm.com/clouddataservices/2016/01/15/real-time-sentiment-analysis-of-twitter-hashtags-with-spark/ ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%%scala\nval demo = com.ibm.cds.spark.samples.StreamingTwitter\ndemo.setConfig(\"twitter4j.oauth.consumerKey\",\"XXXX\")\ndemo.setConfig(\"twitter4j.oauth.consumerSecret\",\"XXXX\")\ndemo.setConfig(\"twitter4j.oauth.accessToken\",\"XXXX)\ndemo.setConfig(\"twitter4j.oauth.accessTokenSecret\",\"XXXX\")\ndemo.setConfig(\"watson.tone.url\",\"https://gateway.watsonplatform.net/tone-analyzer/api\")\ndemo.setConfig(\"watson.tone.password\",\"XXXX\")\ndemo.setConfig(\"watson.tone.username\",\"XXXX\")\n\nimport org.apache.spark.streaming._\ndemo.startTwitterStreaming(sc, Seconds(30))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%%scala\nval demo = com.ibm.cds.spark.samples.StreamingTwitter\nval (__sqlContext, __df) = demo.createTwitterDataFrames(sc)"
        }, 
        {
            "source": "## Do some data science with the DataFrame __df obtained from the scala code above", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "showLegend": "true", 
                        "stacked": "true", 
                        "staticFigure": "false", 
                        "aggregation": "COUNT", 
                        "rowCount": "100", 
                        "handlerId": "barChart", 
                        "valueFields": "Openness", 
                        "keyFields": "Anger"
                    }
                }
            }, 
            "outputs": [], 
            "source": "tweets=__df\ntweets.count()\ndisplay(tweets)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#create an array that will hold the count for each sentiment\nsentimentDistribution=[0] * 13\n#For each sentiment, run a sql query that counts the number of tweets for which the sentiment score is greater than 60%\n#Store the data in the array\nfor i, sentiment in enumerate(tweets.columns[-13:]):\n    sentimentDistribution[i]=__sqlContext.sql(\"SELECT count(*) as sentCount FROM tweets where \" + sentiment + \" > 60\")\\\n        .collect()[0].sentCount"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nind=np.arange(13)\nwidth = 0.35\nbar = plt.bar(ind, sentimentDistribution, width, color='g', label = \"distributions\")\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*2.5, plSize[1]*2) )\nplt.ylabel('Tweet count')\nplt.xlabel('Tone')\nplt.title('Distribution of tweets by sentiments > 60%')\nplt.xticks(ind+width, tweets.columns[-13:])\nplt.legend()\n\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from operator import add\nimport re\ntagsRDD = tweets.flatMap( lambda t: re.split(\"\\s\", t.text))\\\n    .filter( lambda word: word.startswith(\"#\") )\\\n    .map( lambda word : (word, 1 ))\\\n    .reduceByKey(add, 10).map(lambda (a,b): (b,a)).sortByKey(False).map(lambda (a,b):(b,a))\ntop10tags = tagsRDD.take(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*2, plSize[1]*2) )\n\nlabels = [i[0] for i in top10tags]\nsizes = [int(i[1]) for i in top10tags]\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', \"beige\", \"paleturquoise\", \"pink\", \"lightyellow\", \"coral\"]\n\nplt.pie(sizes, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=90)\n\nplt.axis('equal')\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cols = tweets.columns[-13:]\ndef expand( t ):\n    ret = []\n    for s in [i[0] for i in top10tags]:\n        if ( s in t.text ):\n            for tone in cols:\n                ret += [s.replace(':','').replace('-','') + u\"-\" + unicode(tone) + \":\" + unicode(getattr(t, tone))]\n    return ret \ndef makeList(l):\n    return l if isinstance(l, list) else [l]\n\n#Create RDD from tweets dataframe\ntagsRDD = tweets.map(lambda t: t )\n\n#Filter to only keep the entries that are in top10tags\ntagsRDD = tagsRDD.filter( lambda t: any(s in t.text for s in [i[0] for i in top10tags] ) )\n\n#Create a flatMap using the expand function defined above, this will be used to collect all the scores \n#for a particular tag with the following format: Tag-Tone-ToneScore\ntagsRDD = tagsRDD.flatMap( expand )\n\n#Create a map indexed by Tag-Tone keys \ntagsRDD = tagsRDD.map( lambda fullTag : (fullTag.split(\":\")[0], float( fullTag.split(\":\")[1]) ))\n\n#Call combineByKey to format the data as follow\n#Key=Tag-Tone\n#Value=(count, sum_of_all_score_for_this_tone)\ntagsRDD = tagsRDD.combineByKey((lambda x: (x,1)),\n                  (lambda x, y: (x[0] + y, x[1] + 1)),\n                  (lambda x, y: (x[0] + y[0], x[1] + y[1])))\n\n#ReIndex the map to have the key be the Tag and value be (Tone, Average_score) tuple\n#Key=Tag\n#Value=(Tone, average_score)\ntagsRDD = tagsRDD.map(lambda (key, ab): (key.split(\"-\")[0], (key.split(\"-\")[1], round(ab[0]/ab[1], 2))))\n\n#Reduce the map on the Tag key, value becomes a list of (Tone,average_score) tuples\ntagsRDD = tagsRDD.reduceByKey( lambda x, y : makeList(x) + makeList(y) )\n\n#Sort the (Tone,average_score) tuples alphabetically by Tone\ntagsRDD = tagsRDD.mapValues( lambda x : sorted(x) )\n\n#Format the data as expected by the plotting code in the next cell. \n#map the Values to a tuple as follow: ([list of tone], [list of average score])\n#e.g. #someTag:([u'Agreeableness', u'Analytical', u'Anger', u'Cheerfulness', u'Confident', u'Conscientiousness', u'Negative', u'Openness', u'Tentative'], [1.0, 0.0, 0.0, 1.0, 0.0, 0.48, 0.0, 0.02, 0.0])\ntagsRDD = tagsRDD.mapValues( lambda x : ([elt[0] for elt in x],[elt[1] for elt in x])  )\n\n#Use custom sort function to sort the entries by order of appearance in top10tags\ndef customCompare( key ):\n    for (k,v) in top10tags:\n        if k == key:\n            return v\n    return 0\ntagsRDD = tagsRDD.sortByKey(ascending=False, numPartitions=None, keyfunc = customCompare)\n\n#Take the mean tone scores for the top 10 tags\ntop10tagsMeanScores = tagsRDD.take(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*3, plSize[1]*2) )\n\ntop5tagsMeanScores = top10tagsMeanScores[:5]\nwidth = 0\nind=np.arange(13)\n(a,b) = top5tagsMeanScores[0]\nlabels=b[0]\ncolors = [\"beige\", \"paleturquoise\", \"pink\", \"lightyellow\", \"coral\", \"lightgreen\", \"gainsboro\", \"aquamarine\",\"c\"]\nidx=0\nfor key, value in top5tagsMeanScores:\n    plt.bar(ind + width, value[1], 0.15, color=colors[idx], label=key)\n    width += 0.15\n    idx += 1\nplt.xticks(ind+0.3, labels)\nplt.ylabel('AVERAGE SCORE')\nplt.xlabel('TONES')\nplt.title('Breakdown of top hashtags by sentiment tones')\n\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='center',ncol=5, mode=\"expand\", borderaxespad=0.)\n\nplt.show()"
        }, 
        {
            "source": "## Use Twitter demo embedded app to run the same app with a UI", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%%scala\nval demo = com.ibm.cds.spark.samples.PixiedustStreamingTwitter\ndemo.setConfig(\"twitter4j.oauth.consumerKey\",\"XXXX\")\ndemo.setConfig(\"twitter4j.oauth.consumerSecret\",\"XXXX\")\ndemo.setConfig(\"twitter4j.oauth.accessToken\",\"XXXX\")\ndemo.setConfig(\"twitter4j.oauth.accessTokenSecret\",\"XXX\")\ndemo.setConfig(\"watson.tone.url\",\"https://gateway.watsonplatform.net/tone-analyzer/api\")\ndemo.setConfig(\"watson.tone.password\",\"XXXX\")\ndemo.setConfig(\"watson.tone.username\",\"XXXX\")\ndemo.setConfig(\"checkpointDir\", System.getProperty(\"user.home\") + \"/pixiedust/ssc\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "twitterdemo"
                    }
                }
            }, 
            "outputs": [], 
            "source": "from pixiedust_twitterdemo import *\ntwitterDemo()"
        }, 
        {
            "source": "## The embedded app has generated a DataFrame called __tweets. Let's use it to do some data science", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "dataframe"
                    }
                }
            }, 
            "outputs": [], 
            "source": "display(__tweets)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "barChart", 
                        "showLegend": "true", 
                        "valueFields": "score", 
                        "stacked": "true", 
                        "keyFields": "emotion", 
                        "aggregation": "COUNT"
                    }
                }
            }, 
            "outputs": [], 
            "source": "from pyspark.sql import Row\nfrom pyspark.sql.types import *\nemotions=__tweets.columns[-13:]\ndistrib = __tweets.flatMap(lambda t: [(x,t[x]) for x in emotions]).filter(lambda t: t[1]>60)\\\n    .toDF(StructType([StructField('emotion',StringType()),StructField('score',DoubleType())]))\ndisplay(distrib)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "__tweets.registerTempTable(\"pixiedust_tweets\")\n#create an array that will hold the count for each sentiment\nsentimentDistribution=[0] * 13\n#For each sentiment, run a sql query that counts the number of tweets for which the sentiment score is greater than 60%\n#Store the data in the array\nfor i, sentiment in enumerate(__tweets.columns[-13:]):\n    sentimentDistribution[i]=sqlContext.sql(\"SELECT count(*) as sentCount FROM pixiedust_tweets where \" + sentiment + \" > 60\")\\\n        .collect()[0].sentCount"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nind=np.arange(13)\nwidth = 0.35\nbar = plt.bar(ind, sentimentDistribution, width, color='g', label = \"distributions\")\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*2.5, plSize[1]*2) )\nplt.ylabel('Tweet count')\nplt.xlabel('Tone')\nplt.title('Distribution of tweets by sentiments > 60%')\nplt.xticks(ind+width, __tweets.columns[-13:])\nplt.legend()\n\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from operator import add\nimport re\ntagsRDD = __tweets.flatMap( lambda t: re.split(\"\\s\", t.text))\\\n    .filter( lambda word: word.startswith(\"#\") )\\\n    .map( lambda word : (word, 1 ))\\\n    .reduceByKey(add, 10).map(lambda (a,b): (b,a)).sortByKey(False).map(lambda (a,b):(b,a))\ntop10tags = tagsRDD.take(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*2, plSize[1]*2) )\n\nlabels = [i[0] for i in top10tags]\nsizes = [int(i[1]) for i in top10tags]\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', \"beige\", \"paleturquoise\", \"pink\", \"lightyellow\", \"coral\"]\n\nplt.pie(sizes, labels=labels, colors=colors,autopct='%1.1f%%', shadow=True, startangle=90)\n\nplt.axis('equal')\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cols = __tweets.columns[-13:]\ndef expand( t ):\n    ret = []\n    for s in [i[0] for i in top10tags]:\n        if ( s in t.text ):\n            for tone in cols:\n                ret += [s.replace(':','').replace('-','') + u\"-\" + unicode(tone) + \":\" + unicode(getattr(t, tone))]\n    return ret \ndef makeList(l):\n    return l if isinstance(l, list) else [l]\n\n#Create RDD from tweets dataframe\ntagsRDD = __tweets.map(lambda t: t )\n\n#Filter to only keep the entries that are in top10tags\ntagsRDD = tagsRDD.filter( lambda t: any(s in t.text for s in [i[0] for i in top10tags] ) )\n\n#Create a flatMap using the expand function defined above, this will be used to collect all the scores \n#for a particular tag with the following format: Tag-Tone-ToneScore\ntagsRDD = tagsRDD.flatMap( expand )\n\n#Create a map indexed by Tag-Tone keys \ntagsRDD = tagsRDD.map( lambda fullTag : (fullTag.split(\":\")[0], float( fullTag.split(\":\")[1]) ))\n\n#Call combineByKey to format the data as follow\n#Key=Tag-Tone\n#Value=(count, sum_of_all_score_for_this_tone)\ntagsRDD = tagsRDD.combineByKey((lambda x: (x,1)),\n                  (lambda x, y: (x[0] + y, x[1] + 1)),\n                  (lambda x, y: (x[0] + y[0], x[1] + y[1])))\n\n#ReIndex the map to have the key be the Tag and value be (Tone, Average_score) tuple\n#Key=Tag\n#Value=(Tone, average_score)\ntagsRDD = tagsRDD.map(lambda (key, ab): (key.split(\"-\")[0], (key.split(\"-\")[1], round(ab[0]/ab[1], 2))))\n\n#Reduce the map on the Tag key, value becomes a list of (Tone,average_score) tuples\ntagsRDD = tagsRDD.reduceByKey( lambda x, y : makeList(x) + makeList(y) )\n\n#Sort the (Tone,average_score) tuples alphabetically by Tone\ntagsRDD = tagsRDD.mapValues( lambda x : sorted(x) )\n\n#Format the data as expected by the plotting code in the next cell. \n#map the Values to a tuple as follow: ([list of tone], [list of average score])\n#e.g. #someTag:([u'Agreeableness', u'Analytical', u'Anger', u'Cheerfulness', u'Confident', u'Conscientiousness', u'Negative', u'Openness', u'Tentative'], [1.0, 0.0, 0.0, 1.0, 0.0, 0.48, 0.0, 0.02, 0.0])\ntagsRDD = tagsRDD.mapValues( lambda x : ([elt[0] for elt in x],[elt[1] for elt in x])  )\n\n#Use custom sort function to sort the entries by order of appearance in top10tags\ndef customCompare( key ):\n    for (k,v) in top10tags:\n        if k == key:\n            return v\n    return 0\ntagsRDD = tagsRDD.sortByKey(ascending=False, numPartitions=None, keyfunc = customCompare)\n\n#Take the mean tone scores for the top 10 tags\ntop10tagsMeanScores = tagsRDD.take(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nparams = plt.gcf()\nplSize = params.get_size_inches()\nparams.set_size_inches( (plSize[0]*3, plSize[1]*2) )\n\ntop5tagsMeanScores = top10tagsMeanScores[:5]\nwidth = 0\nind=np.arange(13)\n(a,b) = top5tagsMeanScores[0]\nlabels=b[0]\ncolors = [\"beige\", \"paleturquoise\", \"pink\", \"lightyellow\", \"coral\", \"lightgreen\", \"gainsboro\", \"aquamarine\",\"c\"]\nidx=0\nfor key, value in top5tagsMeanScores:\n    plt.bar(ind + width, value[1], 0.15, color=colors[idx], label=key)\n    width += 0.15\n    idx += 1\nplt.xticks(ind+0.3, labels)\nplt.ylabel('AVERAGE SCORE')\nplt.xlabel('TONES')\nplt.title('Breakdown of top hashtags by sentiment tones')\n\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='center',ncol=5, mode=\"expand\", borderaxespad=0.)\n\nplt.show()"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}